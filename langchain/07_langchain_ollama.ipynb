{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain supports many other chat models. Here, we're using Ollama\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# supports many more optional parameters. Hover on your `ChatOllama(...)`\n",
    "# class to view the latest available supported parameters\n",
    "llm = ChatOllama(model=\"llama2:7b-chat\")\n",
    "prompt = ChatPromptTemplate.from_template(\"Tell me a short joke about {topic}\")\n",
    "\n",
    "# using LangChain Expressive Language chain syntax\n",
    "# learn more about the LCEL on\n",
    "# https://python.langchain.com/docs/expression_language/why\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Why did the astronaut break up with his girlfriend before going to Mars?\n",
      "\n",
      "He needed his space!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for brevity, response is printed in terminal\n",
    "# You can use LangServe to deploy your application for\n",
    "# production\n",
    "print(chain.invoke({\"topic\": \"Space travel\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why\n",
      " did\n",
      " the\n",
      " astr\n",
      "onaut\n",
      " break\n",
      " up\n",
      " with\n",
      " his\n",
      " girl\n",
      "friend\n",
      " before\n",
      " going\n",
      " to\n",
      " Mars\n",
      "?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "B\n",
      "ecause\n",
      " he\n",
      " needed\n",
      " his\n",
      " space\n",
      "!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic = {\"topic\": \"Space travel\"}\n",
    "\n",
    "for chunks in chain.stream(topic):\n",
    "    print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a helpful assistant.\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "Human: {input}\n",
    "AI Assistant:\n",
    "\"\"\"  # noqa: E501\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\"], template=template\n",
    ")  # noqa: E501\n",
    "\n",
    "st_callback = StreamlitCallbackHandler(st.container())\n",
    "\n",
    "llm = ChatOllama(model=\"llama2:7b-chat\", callbacks=[StreamingStdOutCallbackHandler()], streaming=True)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    prompt=prompt,\n",
    "    llm=llm,\n",
    "    verbose=False,\n",
    "    memory=ConversationBufferMemory(human_prefix=\"Human\"),\n",
    "    output_parser=StrOutputParser(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm here to help you with any questions you may have. You asked me about the population of Canada, and I'd be happy to provide you with some information.\n",
      "\n",
      "As of 2023, the estimated population of Canada is around 37.7 million people. This number represents approximately 1/9th of the world's total population. The population of Canada is diverse, with a mix of different ethnicities, cultures, and languages.\n",
      "\n",
      "Canada has a relatively low population density compared to other developed countries, with an average of around 4 people per square kilometer. This is due in part to the country's vast geography and natural resources, which have allowed for a more dispersed population.\n",
      "\n",
      "In terms of language, Canada is officially bilingual, with both English and French being recognized as official languages. However, the majority of Canadians speak English as their primary language, while around 20% speak French.\n",
      "\n",
      "I hope this information helps! Do you have any other questions about Canada or its population?"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m conversation\u001b[38;5;241m.\u001b[39mstream({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the population of Canada\u001b[39m\u001b[38;5;124m\"\u001b[39m}):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# print(type(token))\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# print(token)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "for token in conversation.stream({\"input\": \"What is the population of Canada\"}):\n",
    "    # print(type(token))\n",
    "    print(token.content)\n",
    "    # print(token)\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
