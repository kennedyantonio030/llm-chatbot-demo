{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "OPEN_AI_KEY = os.environ.get(\"OPEN_AI_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPEN_AI_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# create a string template with `sample_text` input variable\n",
    "template = \"\"\"You will provided with the sample text. \\\n",
    "Your task is to rewrite the text to be gramatically correct. \\\n",
    "Sample text: ```{sample_text}``` \\\n",
    "Output: \n",
    "\"\"\"\n",
    "# create a prompt template using above-defined template string \n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=template\n",
    ")\n",
    "# specify the `sample_text` variable\n",
    "sample_text = \"Me likes cats not dogs. They jumps high so much!\"\n",
    "# generate a final prompt by passing `sample_text` variable\n",
    "final_prompt = prompt_template.format(\n",
    "    sample_text=sample_text\n",
    ")\n",
    "print(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "\n",
    "# create a string template for a System role with two input variable: `output_language` and `max_words`\n",
    "system_template = \"\"\"You will provided with the sample text. \\\n",
    "Your task is to translate the text into {output_language} language \\\n",
    "and summarize the translated text in at most {max_words} words. \\ \n",
    "\"\"\"\n",
    "# create a prompt template for a System role\n",
    "system_message_prompt_template = SystemMessagePromptTemplate.from_template(\n",
    "    system_template)\n",
    "# create a string template for a System role with `sample_text` input variable\n",
    "human_template = \"{sample_text}\"\n",
    "# create a prompt template for a Human role\n",
    "human_message_prompt_template = HumanMessagePromptTemplate.from_template(human_template)\n",
    "# create chat prompt template out of one or several message prompt templates\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt_template, human_message_prompt_template])\n",
    "# generate a final prompt by passing all three variables (`output_language`,  `max_words`, `sample_text`)\n",
    "final_prompt = chat_prompt_template.format_prompt(output_language=\"English\", max_words=15,\n",
    "                          sample_text=\"Estoy deseando que llegue el fin de semana.\").to_messages()\n",
    "print(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "\n",
    "# initialize ChatGPT model\n",
    "chat = ChatOpenAI(temperature=0)\n",
    "system_template = \"\"\"You will provided with the sample text. \\\n",
    "Your task is to translate the text into {output_language} language \\\n",
    "and summarize the translated text in at most {max_words} words. \\ \n",
    "\"\"\"\n",
    "system_message_prompt_template = SystemMessagePromptTemplate.from_template(\n",
    "    system_template)\n",
    "human_template = \"{sample_text}\"\n",
    "human_message_prompt_template = HumanMessagePromptTemplate.from_template(human_template)\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt_template, human_message_prompt_template])\n",
    "final_prompt = chat_prompt_template.format_prompt(output_language=\"English\", max_words=15,\n",
    "                          sample_text=\"Estoy deseando que llegue el fin de semana.\").to_messages()\n",
    "# generate the output by calling ChatGPT model and passing the prompt\n",
    "completion = chat(final_prompt)\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# initialize OpenAI embedding model\n",
    "embeddings = OpenAIEmbeddings(model = \"text-embedding-ada-002\")\n",
    "# create a text to be embedded\n",
    "text = \"It is imperative that we work towards sustainable practices, reducing waste and conserving resources.\"\n",
    "# generate embedding by calling OpenAI embedding model and passing the text\n",
    "embedded_text = embeddings.embed_query(text)\n",
    "print(embedded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "# saving conversation\n",
    "memory.save_context({\"input\": \"Describe LSTM\"}, {\n",
    "                    \"output\": \"LSTM is a type of recurrent neural network architecture that is widely used for sequential and time series data processing.\"})\n",
    "# retrieving conversation from a memory\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
