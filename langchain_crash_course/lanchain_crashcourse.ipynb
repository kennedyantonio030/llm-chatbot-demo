{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c26845d",
   "metadata": {},
   "source": [
    "# Langchain crash course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f31c4cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87a6ede8",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed0dc6a",
   "metadata": {},
   "source": [
    "## LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa352d5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Taj Mahal Spice Co.\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.9)\n",
    "name = llm.invoke(\"I want to open a restaurant for Indian food. Suggest a fency name for this.\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b56e8581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"Spice and Splendor: Fine Indian Cuisine\" '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"I want to open a restaurant for Indian food. Suggest a fency name for this.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0782a2dd",
   "metadata": {},
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a306b9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to open a restaurant for Italian food. Suggest a fency name for this.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables =['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
    ")\n",
    "p = prompt_template_name.format(cuisine=\"Italian\")\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af406b92",
   "metadata": {},
   "source": [
    "## Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba65c213",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"cuisine\": \"Mexican\",\n",
      "    \"text\": \"\\n\\n\\\"El Jard\\u00edn de Sabores\\\" (The Garden of Flavors)\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "results = chain.invoke(\"Mexican\")\n",
    "print(json.dumps(results, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5ccee75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mI want to open a restaurant for Mexican food. Suggest a fency name for this.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{\n",
      "    \"cuisine\": \"Mexican\",\n",
      "    \"text\": \"\\n\\n\\\"El Sabor Exquisito\\\"\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt_template_name, verbose=True)\n",
    "results = chain.invoke(\"Mexican\")\n",
    "print(json.dumps(results, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21098937",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.6)\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables =['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
    ")\n",
    "\n",
    "name_chain =LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = ['restaurant_name'],\n",
    "    template=\"\"\"Suggest some menu items for {restaurant_name}\"\"\"\n",
    ")\n",
    "\n",
    "food_items_chain = LLMChain(llm=llm, prompt=prompt_template_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a98d9f",
   "metadata": {},
   "source": [
    "#### Simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9fd9a79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indian\n",
      "('\\n'\n",
      " '\\n'\n",
      " '1. Spicy Chicken Tikka Masala\\n'\n",
      " '2. Vegetable Samosas\\n'\n",
      " '3. Lamb Vindaloo\\n'\n",
      " '4. Tandoori Shrimp\\n'\n",
      " '5. Palak Paneer (spinach and cheese curry)\\n'\n",
      " '6. Aloo Gobi (potato and cauliflower curry)\\n'\n",
      " '7. Bhindi Masala (spicy okra)\\n'\n",
      " '8. Naan bread with garlic or chili\\n'\n",
      " '9. Mango Lassi (yogurt drink)\\n'\n",
      " '10. Chai Tea\\n'\n",
      " '11. Chicken Biryani\\n'\n",
      " '12. Achari Paneer (pickled cheese curry)\\n'\n",
      " '13. Malai Kofta (vegetable and cheese dumplings in creamy sauce)\\n'\n",
      " '14. Tandoori Chicken\\n'\n",
      " '15. Masala Chai Ice Cream for dessert.')\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "chain = SimpleSequentialChain(chains = [name_chain, food_items_chain])\n",
    "\n",
    "results = chain.invoke(\"Indian\")\n",
    "print(results[\"input\"])\n",
    "pprint(results[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0386d05c",
   "metadata": {},
   "source": [
    "#### Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49dc0fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.7)\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables =['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
    ")\n",
    "\n",
    "name_chain =LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"restaurant_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dea8402",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.7)\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = ['restaurant_name'],\n",
    "    template=\"Suggest some menu items for {restaurant_name}.\"\n",
    ")\n",
    "\n",
    "food_items_chain =LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"menu_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ec1be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain = SequentialChain(\n",
    "    chains = [name_chain, food_items_chain],\n",
    "    input_variables = ['cuisine'],\n",
    "    output_variables = ['restaurant_name', \"menu_items\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4653c540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Indian'\n",
      "'\\n\\n\"Royal Masala\" '\n",
      "('\\n'\n",
      " '1. Chicken Tikka Masala\\n'\n",
      " '2. Vegetable Korma\\n'\n",
      " '3. Lamb Vindaloo\\n'\n",
      " '4. Palak Paneer\\n'\n",
      " '5. Garlic Naan\\n'\n",
      " '6. Tandoori Chicken\\n'\n",
      " '7. Samosas\\n'\n",
      " '8. Chana Masala\\n'\n",
      " '9. Butter Chicken\\n'\n",
      " '10. Aloo Gobi\\n'\n",
      " '11. Mango Lassi\\n'\n",
      " '12. Malai Kofta\\n'\n",
      " '13. Dal Makhani\\n'\n",
      " '14. Biryani\\n'\n",
      " '15. Gulab Jamun (dessert)')\n"
     ]
    }
   ],
   "source": [
    "results = chain.invoke({\"cuisine\": \"Indian\"})\n",
    "pprint(results[\"cuisine\"])\n",
    "pprint(results[\"restaurant_name\"])\n",
    "pprint(results[\"menu_items\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4069a75e",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e6ee719",
   "metadata": {},
   "outputs": [],
   "source": [
    "SERPAPI_API_KEY = os.environ.get('SERPAPI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471b2c6b",
   "metadata": {},
   "source": [
    "#### serpapi and llm-math tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddcab683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentType, create_react_agent, load_tools, AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a71e6fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"hwchase17/react\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fec4212d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should search for the answer using a search engine.\n",
      "Action: Search\n",
      "Action Input: \"GDP of US in 2022\"\u001b[0m\u001b[36;1m\u001b[1;3m25439.70 USD Billion\u001b[0m\u001b[32;1m\u001b[1;3m I should use a calculator to convert the result to a more readable format.\n",
      "Action: Calculator\n",
      "Action Input: 25439.70 * 1000000000\u001b[0m\u001b[33;1m\u001b[1;3mAnswer: 25439700000000.0\u001b[0m\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The GDP of US in 2022 is 25.44 trillion USD.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What was the GDP of US in 2022?',\n",
       " 'output': 'The GDP of US in 2022 is 25.44 trillion USD.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "\n",
    "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
    "agent = create_react_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "query = \"What was the GDP of US in 2022?\"\n",
    "\n",
    "# Let's test it out!\n",
    "agent_executor.invoke(input={\"input\": query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cd3a12",
   "metadata": {},
   "source": [
    "#### Wikipedia and llm-math tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14d06ce6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use Wikipedia to find out when Elon Musk was born and then use a calculator to find the square root of his age.\n",
      "Action: Wikipedia\n",
      "Action Input: Elon Musk\u001b[0m\u001b[36;1m\u001b[1;3mPage: Elon Musk\n",
      "Summary: Elon Reeve Musk ( EE-lon; born June 28, 1971) is a businessman and investor. He is the founder, chairman, CEO, and CTO of SpaceX; angel investor, CEO, product architect and former chairman of Tesla, Inc.; owner, chairman and CTO of X Corp.; founder of the Boring Company and xAI; co-founder of Neuralink and OpenAI; and president of the Musk Foundation. He is the wealthiest person in the world, with an estimated net worth of US$232 billion as of December 2023, according to the Bloomberg Billionaires Index, and $254 billion according to Forbes, primarily from his ownership stakes in Tesla and SpaceX.A member of the wealthy South African Musk family, Elon was born in Pretoria and briefly attended the University of Pretoria before immigrating to Canada at age 18, acquiring citizenship through his Canadian-born mother. Two years later, he matriculated at Queen's University at Kingston in Canada. Musk later transferred to the University of Pennsylvania, and received bachelor's degrees in economics and physics. He moved to California in 1995 to attend Stanford University. However, Musk dropped out after two days and, with his brother Kimbal, co-founded online city guide software company Zip2. The startup was acquired by Compaq for $307 million in 1999, and, that same year Musk co-founded X.com, a direct bank. X.com merged with Confinity in 2000 to form PayPal.\n",
      "In October 2002, eBay acquired PayPal for $1.5 billion, and that same year, with $100 million of the money he made, Musk founded SpaceX, a spaceflight services company. In 2004, he became an early investor in electric vehicle manufacturer Tesla Motors, Inc. (now Tesla, Inc.). He became its chairman and product architect, assuming the position of CEO in 2008. In 2006, Musk helped create SolarCity, a solar-energy company that was acquired by Tesla in 2016 and became Tesla Energy. In 2013, he proposed a hyperloop high-speed vactrain transportation system. In 2015, he co-founded OpenAI, a nonprofit artificial intelligence research company. The following year, Musk co-founded Neuralink—a neurotechnology company developing brain–computer interfaces—and the Boring Company, a tunnel construction company. In 2022, he acquired Twitter for $44 billion. He subsequently merged the company into newly created X Corp. and rebranded the service as X the following year. In March 2023, he founded xAI, an artificial intelligence company.\n",
      "Musk has expressed views that have made him a polarizing figure. He has been criticized for making unscientific and misleading statements, including COVID-19 misinformation, and antisemitic conspiracy theories. His ownership of Twitter has been similarly controversial, being marked by the laying off of a large number of employees, an increase in hate speech and misinformation and disinformation on the website, as well as changes to Twitter Blue verification. In 2018, the U.S. Securities and Exchange Commission (SEC) sued him for falsely tweeting that he had secured funding for a private takeover of Tesla. To settle the case, Musk stepped down as the chairman of Tesla and paid a $20 million fine.\n",
      "\n",
      "\n",
      "\n",
      "Page: Acquisition of Twitter by Elon Musk\n",
      "Summary: Business magnate Elon Musk initiated an acquisition of American social media company Twitter, Inc. on April 14, 2022, and concluded it on October 27, 2022. Musk had begun buying shares of the company in January 2022, becoming its largest shareholder by April with a 9.1 percent ownership stake. Twitter invited Musk to join its board of directors, an offer he initially accepted before declining. On April 14, Musk made an unsolicited offer to purchase the company, to which Twitter's board responded with a \"poison pill\" strategy to resist a hostile takeover before unanimously accepting Musk's buyout offer of $44 billion on April 25. Musk stated that he planned to introduce new features to the platform, make its algorithms open-source, combat spambot accounts, and promote free speech.\n",
      "In July, Musk an\u001b[0m\u001b[32;1m\u001b[1;3m I now know that Elon Musk was born on June 28, 1971 and that he will be 52 years old in 2023.\n",
      "Action: Calculator\n",
      "Action Input: Square root of 52\u001b[0m\u001b[33;1m\u001b[1;3mAnswer: 7.211102550927978\u001b[0m\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The square root of Elon Musk's age as of 2023 is approximately 7.21.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'When was Elon musk born? What is the square root of his age as of 2023?',\n",
       " 'output': \"The square root of Elon Musk's age as of 2023 is approximately 7.21.\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# install this package: pip install wikipedia\n",
    "\n",
    "# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n",
    "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)\n",
    "\n",
    "agent = create_react_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "query = \"When was Elon musk born? What is the square root of his age as of 2023?\"\n",
    "\n",
    "# Let's test it out!\n",
    "agent_executor.invoke(input={\"input\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0c9bec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.99999999999999"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7.211102550927978 ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6be7ee7",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871492be",
   "metadata": {},
   "source": [
    "#### ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53eea298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cuisine': 'Mexican', 'history': '', 'text': '\\n\\n\"El Sabor Exquisito\" (The Exquisite Flavor)'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template_name, memory=memory)\n",
    "name = chain.invoke(\"Mexican\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0de5d50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cuisine': 'Arabic', 'history': 'Human: Mexican\\nAI: \\n\\n\"El Sabor Exquisito\" (The Exquisite Flavor)', 'text': '\\n\\n\"Al-Fawarish\" (meaning \"The Treasures\" in Arabic)'}\n"
     ]
    }
   ],
   "source": [
    "name = chain.invoke(\"Arabic\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cc88888",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Mexican\n",
      "AI: \n",
      "\n",
      "\"El Sabor Exquisito\" (The Exquisite Flavor)\n",
      "Human: Arabic\n",
      "AI: \n",
      "\n",
      "\"Al-Fawarish\" (meaning \"The Treasures\" in Arabic)\n"
     ]
    }
   ],
   "source": [
    "print(chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a88b5b",
   "metadata": {},
   "source": [
    "#### ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "687ddd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "convo = ConversationChain(llm=OpenAI(temperature=0.7))\n",
    "print(convo.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47ad5062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Who won the first cricket world cup?',\n",
       " 'history': '',\n",
       " 'response': \" The first cricket world cup was held in 1975 and was won by the West Indies team. They defeated Australia in the final by 17 runs. The tournament was hosted by England, with a total of eight teams participating. The West Indies team was led by Clive Lloyd and had players such as Viv Richards and Gordon Greenidge. The final was held at Lord's Cricket Ground in London, England. It was a historic moment for the sport of cricket and the West Indies team was hailed as champions.\"}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.invoke(\"Who won the first cricket world cup?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03c80b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'How much is 5+5?',\n",
       " 'history': \"Human: Who won the first cricket world cup?\\nAI:  The first cricket world cup was held in 1975 and was won by the West Indies team. They defeated Australia in the final by 17 runs. The tournament was hosted by England, with a total of eight teams participating. The West Indies team was led by Clive Lloyd and had players such as Viv Richards and Gordon Greenidge. The final was held at Lord's Cricket Ground in London, England. It was a historic moment for the sport of cricket and the West Indies team was hailed as champions.\",\n",
       " 'response': ' The answer to 5+5 is 10. This is a basic arithmetic problem and the result is a simple addition of the two numbers. '}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.invoke(\"How much is 5+5?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07342f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Who was the captain ofthe winning team?',\n",
       " 'history': \"Human: Who won the first cricket world cup?\\nAI:  The first cricket world cup was held in 1975 and was won by the West Indies team. They defeated Australia in the final by 17 runs. The tournament was hosted by England, with a total of eight teams participating. The West Indies team was led by Clive Lloyd and had players such as Viv Richards and Gordon Greenidge. The final was held at Lord's Cricket Ground in London, England. It was a historic moment for the sport of cricket and the West Indies team was hailed as champions.\\nHuman: How much is 5+5?\\nAI:  The answer to 5+5 is 10. This is a basic arithmetic problem and the result is a simple addition of the two numbers. \",\n",
       " 'response': ' The captain of the winning team was Clive Lloyd. He was a legendary cricketer for the West Indies team and led them to two consecutive World Cup victories in 1975 and 1979. He was known for his strong leadership skills and his powerful batting style. He was also known as the \"Supercat\" for his excellent fielding abilities.'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.invoke(\"Who was the captain ofthe winning team?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e459d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Who won the first cricket world cup?\n",
      "AI:  The first cricket world cup was held in 1975 and was won by the West Indies team. They defeated Australia in the final by 17 runs. The tournament was hosted by England, with a total of eight teams participating. The West Indies team was led by Clive Lloyd and had players such as Viv Richards and Gordon Greenidge. The final was held at Lord's Cricket Ground in London, England. It was a historic moment for the sport of cricket and the West Indies team was hailed as champions.\n",
      "Human: How much is 5+5?\n",
      "AI:  The answer to 5+5 is 10. This is a basic arithmetic problem and the result is a simple addition of the two numbers. \n",
      "Human: Who was the captain ofthe winning team?\n",
      "AI:  The captain of the winning team was Clive Lloyd. He was a legendary cricketer for the West Indies team and led them to two consecutive World Cup victories in 1975 and 1979. He was known for his strong leadership skills and his powerful batting style. He was also known as the \"Supercat\" for his excellent fielding abilities.\n"
     ]
    }
   ],
   "source": [
    "print(convo.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaa3abd",
   "metadata": {},
   "source": [
    "#### ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "460eb33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Who won the first cricket world cup?',\n",
       " 'history': '',\n",
       " 'response': ' The first cricket world cup was held in 1975 and was won by the West Indies. The event took place in England and was hosted by the International Cricket Council. The West Indies defeated Australia in the final match by 17 runs. It was a historic moment for the West Indies as they became the first ever winners of the cricket world cup.'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "\n",
    "convo = ConversationChain(\n",
    "    llm=OpenAI(temperature=0.7),\n",
    "    memory=memory\n",
    ")\n",
    "convo.invoke(\"Who won the first cricket world cup?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d395beaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'How much is 5+5?',\n",
       " 'history': 'Human: Who won the first cricket world cup?\\nAI:  The first cricket world cup was held in 1975 and was won by the West Indies. The event took place in England and was hosted by the International Cricket Council. The West Indies defeated Australia in the final match by 17 runs. It was a historic moment for the West Indies as they became the first ever winners of the cricket world cup.',\n",
       " 'response': '  5+5 is equal to 10.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.invoke(\"How much is 5+5?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93b24745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Who was the captain of the winning team?',\n",
       " 'history': 'Human: How much is 5+5?\\nAI:   5+5 is equal to 10.',\n",
       " 'response': ' I am not sure which specific team you are referring to. Can you provide more context?'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.invoke(\"Who was the captain of the winning team?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cd907d",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "047f239e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: What is your name?\n",
      "AI:  My specific name is determined by my creators and programmers. They have given me the name AI, but I am constantly learning and evolving, so my abilities and knowledge are always expanding. Is there something else you would like to know?\n"
     ]
    }
   ],
   "source": [
    "for chunk in convo.stream(\"Write me a song about goldfish on the moon\"):\n",
    "    print(chunk[\"history\"])\n",
    "    # print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "66d61341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_community.llms import GPT4All\n",
    "\n",
    "# Set up the prompt template\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "# Set up the local instace of the LLM\n",
    "local_path = \"/Users/brianroepke/Library/Application Support/nomic.ai/GPT4All/mistral-7b-openorca.Q4_0.gguf\"  # noqa: E501\n",
    "callbacks = [StreamingStdOutCallbackHandler()]\n",
    "memory = ConversationBufferMemory()\n",
    "llm = GPT4All(model=local_path, callbacks=callbacks, verbose=True, streaming=True)  # noqa: E501\n",
    "# llm_chain = LLMChain(llm=llm, prompt=prompt, memory=memory)\n",
    "\n",
    "llm_chain = ConversationChain(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "842b2f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sure! Here's a little ditty I came up with:\n",
      "\n",
      "Sparkling Water Lullaby\n",
      "(To the tune of Twinkle, Twinkle Little Star)\n",
      "\n",
      "Sparkling water so clear and bright,\n",
      "Bubbles dance in the moonlight,\n",
      "Quenching thirst on a summer night.\n",
      "\n",
      "Chorus:\n",
      "Drink it down, drink it up,\n",
      "Feel your body tingle with delight!\n",
      "Sparkling water is so right!\n",
      "\n",
      "In the meadow where daisies play,\n",
      "A cool stream flows all day,\n",
      "Filling glasses for passersby.\n",
      "\n",
      "Chorus: Drink it down...\n",
      "\n",
      "On a mountain peak so high,\n",
      "Icicles glisten in the sky,\n",
      "Melting into sparkling water.\n",
      "\n",
      "Chorus: Drink it down...\n",
      "\n",
      "In the depths of the ocean blue,\n",
      "A school of fish come swimming through,\n",
      "Drinking from fountains made for two.\n",
      "\n",
      "Chorus: Drink it down...\n",
      "\n",
      "So next time you're parched and dry,\n",
      "Remember sparkling water's why,\n",
      "It quenches thirst with every sigh!\n",
      "{'input': 'Write me a song about sparkling water.', 'history': '', 'response': \" Sure! Here's a little ditty I came up with:\\n\\nSparkling Water Lullaby\\n(To the tune of Twinkle, Twinkle Little Star)\\n\\nSparkling water so clear and bright,\\nBubbles dance in the moonlight,\\nQuenching thirst on a summer night.\\n\\nChorus:\\nDrink it down, drink it up,\\nFeel your body tingle with delight!\\nSparkling water is so right!\\n\\nIn the meadow where daisies play,\\nA cool stream flows all day,\\nFilling glasses for passersby.\\n\\nChorus: Drink it down...\\n\\nOn a mountain peak so high,\\nIcicles glisten in the sky,\\nMelting into sparkling water.\\n\\nChorus: Drink it down...\\n\\nIn the depths of the ocean blue,\\nA school of fish come swimming through,\\nDrinking from fountains made for two.\\n\\nChorus: Drink it down...\\n\\nSo next time you're parched and dry,\\nRemember sparkling water's why,\\nIt quenches thirst with every sigh!\\n\"}"
     ]
    }
   ],
   "source": [
    "for chunk in llm_chain.stream(\"Write me a song about sparkling water.\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b9ff5b70",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ConversationChain\n__root__\n  Got unexpected prompt input variables. The prompt expects [], but got ['history'] as inputs from memory, and input as the normal input key. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m system_message \u001b[38;5;241m=\u001b[39m SystemMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAct as a Recruiter for a Big Tech Startup\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate(messages\u001b[38;5;241m=\u001b[39m[system_message])\n\u001b[0;32m---> 13\u001b[0m conversation \u001b[38;5;241m=\u001b[39m \u001b[43mConversationChain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchat_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minput\u001b[39m(human_response):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m conversation\u001b[38;5;241m.\u001b[39mrun(human_response)\n",
      "File \u001b[0;32m~/Projects/deadpool-llm/venv/lib/python3.11/site-packages/langchain_core/load/serializable.py:107\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ConversationChain\n__root__\n  Got unexpected prompt input variables. The prompt expects [], but got ['history'] as inputs from memory, and input as the normal input key. (type=value_error)"
     ]
    }
   ],
   "source": [
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "\n",
    "chat_model = ChatOpenAI()\n",
    "system_message = SystemMessage(content=\"Act as a Recruiter for a Big Tech Startup\")\n",
    "\n",
    "prompt = ChatPromptTemplate(messages=[system_message])\n",
    "\n",
    "conversation = ConversationChain(llm=chat_model, prompt=prompt, verbose=True)\n",
    "\n",
    "def input(human_response):\n",
    "    return conversation.run(human_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9292a00c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
