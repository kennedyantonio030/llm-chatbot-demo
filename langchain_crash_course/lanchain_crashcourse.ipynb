{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c26845d",
   "metadata": {},
   "source": [
    "# Langchain crash course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f31c4cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87a6ede8",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed0dc6a",
   "metadata": {},
   "source": [
    "## LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa352d5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Taj Mahal Spice House\" \n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.9)\n",
    "name = llm.invoke(\"I want to open a restaurant for Indian food. Suggest a fency name for this.\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b56e8581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\"Spice Delight\"'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"I want to open a restaurant for Indian food. Suggest a fency name for this.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0782a2dd",
   "metadata": {},
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a306b9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to open a restaurant for Italian food. Suggest a fency name for this.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables =['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
    ")\n",
    "p = prompt_template_name.format(cuisine=\"Italian\")\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af406b92",
   "metadata": {},
   "source": [
    "## Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba65c213",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"cuisine\": \"Mexican\",\n",
      "    \"text\": \"\\n\\\"Cantina del Sol\\\"\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "results = chain.invoke(\"Mexican\")\n",
    "print(json.dumps(results, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5ccee75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mI want to open a restaurant for Mexican food. Suggest a fency name for this.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{\n",
      "    \"cuisine\": \"Mexican\",\n",
      "    \"text\": \"\\n\\n\\\"El Sabor Del Sol\\\" (The Flavor of the Sun)\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt_template_name, verbose=True)\n",
    "results = chain.invoke(\"Mexican\")\n",
    "print(json.dumps(results, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21098937",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.6)\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables =['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
    ")\n",
    "\n",
    "name_chain =LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = ['restaurant_name'],\n",
    "    template=\"\"\"Suggest some menu items for {restaurant_name}\"\"\"\n",
    ")\n",
    "\n",
    "food_items_chain = LLMChain(llm=llm, prompt=prompt_template_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a98d9f",
   "metadata": {},
   "source": [
    "#### Simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9fd9a79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indian\n",
      "('1. Chicken Tikka Masala: Tender pieces of chicken cooked in a creamy '\n",
      " 'tomato-based sauce, served with basmati rice.\\n'\n",
      " '\\n'\n",
      " '2. Vegetable Biryani: Fragrant basmati rice cooked with an assortment of '\n",
      " 'vegetables, nuts, and spices.\\n'\n",
      " '\\n'\n",
      " '3. Tandoori Shrimp: Succulent shrimp marinated in yogurt and spices, cooked '\n",
      " 'in a traditional clay oven.\\n'\n",
      " '\\n'\n",
      " '4. Palak Paneer: Creamy spinach and cottage cheese dish, served with naan '\n",
      " 'bread.\\n'\n",
      " '\\n'\n",
      " '5. Lamb Rogan Josh: Slow-cooked lamb in a rich and flavorful tomato-based '\n",
      " 'sauce, served with rice or naan.\\n'\n",
      " '\\n'\n",
      " '6. Aloo Gobi: Cauliflower and potato curry with a blend of aromatic spices.\\n'\n",
      " '\\n'\n",
      " '7. Samosas: Crispy pastry filled with spiced potatoes and peas, served with '\n",
      " 'chutney for dipping.\\n'\n",
      " '\\n'\n",
      " '8. Malai Kofta: Vegetable and cheese dumplings in a creamy cashew and tomato '\n",
      " 'sauce.\\n'\n",
      " '\\n'\n",
      " '9. Butter Chicken: Tender chicken pieces in a rich and buttery tomato-based '\n",
      " 'sauce, served with rice or naan.\\n'\n",
      " '\\n'\n",
      " '10. Mango Lassi: A refreshing drink made with yogurt, mango, and a touch of '\n",
      " 'cardamom.')\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "chain = SimpleSequentialChain(chains = [name_chain, food_items_chain])\n",
    "\n",
    "results = chain.invoke(\"Indian\")\n",
    "print(results[\"input\"])\n",
    "pprint(results[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0386d05c",
   "metadata": {},
   "source": [
    "#### Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49dc0fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.7)\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables =['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
    ")\n",
    "\n",
    "name_chain =LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"restaurant_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dea8402",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.7)\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = ['restaurant_name'],\n",
    "    template=\"Suggest some menu items for {restaurant_name}.\"\n",
    ")\n",
    "\n",
    "food_items_chain =LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"menu_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ec1be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain = SequentialChain(\n",
    "    chains = [name_chain, food_items_chain],\n",
    "    input_variables = ['cuisine'],\n",
    "    output_variables = ['restaurant_name', \"menu_items\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4653c540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Indian'\n",
      "'\\n\\n\"Taste of India\"'\n",
      "('\\n'\n",
      " '\\n'\n",
      " '1. Chicken Tikka Masala\\n'\n",
      " '2. Vegetable Samosas\\n'\n",
      " '3. Lamb Vindaloo\\n'\n",
      " '4. Palak Paneer (spinach and cottage cheese)\\n'\n",
      " '5. Tandoori Chicken\\n'\n",
      " '6. Naan bread\\n'\n",
      " '7. Aloo Gobi (potato and cauliflower)\\n'\n",
      " '8. Chana Masala (chickpea curry)\\n'\n",
      " '9. Butter Chicken\\n'\n",
      " '10. Vegetable Biryani\\n'\n",
      " '11. Mango Lassi (yogurt drink)\\n'\n",
      " '12. Gulab Jamun (sweet dessert)\\n'\n",
      " '13. Tandoori Fish\\n'\n",
      " '14. Dal Makhani (lentil curry)\\n'\n",
      " '15. Chicken Korma.')\n"
     ]
    }
   ],
   "source": [
    "results = chain.invoke({\"cuisine\": \"Indian\"})\n",
    "pprint(results[\"cuisine\"])\n",
    "pprint(results[\"restaurant_name\"])\n",
    "pprint(results[\"menu_items\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4069a75e",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e6ee719",
   "metadata": {},
   "outputs": [],
   "source": [
    "SERPAPI_API_KEY = os.environ.get('SERPAPI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471b2c6b",
   "metadata": {},
   "source": [
    "#### serpapi and llm-math tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddcab683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentType, create_react_agent, load_tools, AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a71e6fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'], template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fec4212d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should search for the answer using a search engine.\n",
      "Action: Search\n",
      "Action Input: \"GDP of US in 2022\"\u001b[0m\u001b[36;1m\u001b[1;3m$25.46 trillion\u001b[0m\u001b[32;1m\u001b[1;3mI should use a calculator to convert the GDP from dollars to another currency if needed.\n",
      "Action: Calculator\n",
      "Action Input: $25.46 trillion\u001b[0m\u001b[33;1m\u001b[1;3mAnswer: 25460000000000.0\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: The GDP of US in 2022 was $25.46 trillion.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What was the GDP of US in 2022?',\n",
       " 'output': 'The GDP of US in 2022 was $25.46 trillion.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "\n",
    "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
    "agent = create_react_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "query = \"What was the GDP of US in 2022?\"\n",
    "\n",
    "# Let's test it out!\n",
    "agent_executor.invoke(input={\"input\": query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cd3a12",
   "metadata": {},
   "source": [
    "#### Wikipedia and llm-math tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14d06ce6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use Wikipedia to find out when Elon Musk was born and then use a calculator to find the square root of his age.\n",
      "Action: Wikipedia\n",
      "Action Input: Elon Musk\u001b[0m\u001b[36;1m\u001b[1;3mPage: Elon Musk\n",
      "Summary: Elon Reeve Musk (; EE-lon; born June 28, 1971) is a businessman and investor. He is the founder, chairman, CEO, and CTO of SpaceX; angel investor, CEO, product architect and former chairman of Tesla, Inc.; owner, chairman and CTO of X Corp.; founder of the Boring Company and xAI; co-founder of Neuralink and OpenAI; and president of the Musk Foundation. He is the wealthiest person in the world, with an estimated net worth of US$232 billion as of December 2023, according to the Bloomberg Billionaires Index, and $254 billion according to Forbes, primarily from his ownership stakes in Tesla and SpaceX.A member of the wealthy South African Musk family, Elon was born in Pretoria and briefly attended the University of Pretoria before immigrating to Canada at age 18, acquiring citizenship through his Canadian-born mother. Two years later, he matriculated at Queen's University at Kingston in Canada. Musk later transferred to the University of Pennsylvania, and received bachelor's degrees in economics and physics. He moved to California in 1995 to attend Stanford University. However, Musk dropped out after two days and, with his brother Kimbal, co-founded online city guide software company Zip2. The startup was acquired by Compaq for $307 million in 1999, and, that same year Musk co-founded X.com, a direct bank. X.com merged with Confinity in 2000 to form PayPal.\n",
      "In October 2002, eBay acquired PayPal for $1.5 billion, and that same year, with $100 million of the money he made, Musk founded SpaceX, a spaceflight services company. In 2004, he became an early investor in electric vehicle manufacturer Tesla Motors, Inc. (now Tesla, Inc.). He became its chairman and product architect, assuming the position of CEO in 2008. In 2006, Musk helped create SolarCity, a solar-energy company that was acquired by Tesla in 2016 and became Tesla Energy. In 2013, he proposed a hyperloop high-speed vactrain transportation system. In 2015, he co-founded OpenAI, a nonprofit artificial intelligence research company. The following year, Musk co-founded Neuralink—a neurotechnology company developing brain–computer interfaces—and the Boring Company, a tunnel construction company. In 2022, he acquired Twitter for $44 billion. He subsequently merged the company into newly created X Corp. and rebranded the service as X the following year. In March 2023, he founded xAI, an artificial intelligence company.\n",
      "Musk has expressed views that have made him a polarizing figure. He has been criticized for making unscientific and misleading statements, including COVID-19 misinformation, and antisemitic conspiracy theories. His ownership of Twitter has been similarly controversial, being marked by the laying off of a large number of employees, an increase in hate speech and misinformation and disinformation on the website, as well as changes to Twitter Blue verification. In 2018, the U.S. Securities and Exchange Commission (SEC) sued him for falsely tweeting that he had secured funding for a private takeover of Tesla. To settle the case, Musk stepped down as the chairman of Tesla and paid a $20 million fine.\n",
      "\n",
      "\n",
      "\n",
      "Page: Acquisition of Twitter by Elon Musk\n",
      "Summary: Business magnate Elon Musk initiated an acquisition of American social media company Twitter, Inc. on April 14, 2022, and concluded it on October 27, 2022. Musk had begun buying shares of the company in January 2022, becoming its largest shareholder by April with a 9.1 percent ownership stake. Twitter invited Musk to join its board of directors, an offer he initially accepted before declining. On April 14, Musk made an unsolicited offer to purchase the company, to which Twitter's board responded with a \"poison pill\" strategy to resist a hostile takeover before unanimously accepting Musk's buyout offer of $44 billion on April 25. Musk stated that he planned to introduce new features to the platform, make its algorithms open-source, combat spambot accounts, and promote free speech.\n",
      "In July, Musk a\u001b[0m\u001b[32;1m\u001b[1;3m I now know that Elon Musk was born on June 28, 1971 and that he will be 52 years old in 2023.\n",
      "Action: Calculator\n",
      "Action Input: Square root of 52\u001b[0m\u001b[33;1m\u001b[1;3mAnswer: 7.211102550927978\u001b[0m\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The square root of Elon Musk's age as of 2023 is approximately 7.21.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'When was Elon musk born? What is the square root of his age as of 2023?',\n",
       " 'output': \"The square root of Elon Musk's age as of 2023 is approximately 7.21.\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# install this package: pip install wikipedia\n",
    "\n",
    "# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n",
    "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)\n",
    "\n",
    "agent = create_react_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "query = \"When was Elon musk born? What is the square root of his age as of 2023?\"\n",
    "\n",
    "# Let's test it out!\n",
    "agent_executor.invoke(input={\"input\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0c9bec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.99999999999999"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7.211102550927978 ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6be7ee7",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871492be",
   "metadata": {},
   "source": [
    "#### ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53eea298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cuisine': 'Mexican', 'history': '', 'text': '\\n\\n\"El Sabor Exquisito\" (The Exquisite Flavor)'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template_name, memory=memory)\n",
    "name = chain.invoke(\"Mexican\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0de5d50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cuisine': 'Arabic', 'history': 'Human: Mexican\\nAI: \\n\\n\"El Sabor Exquisito\" (The Exquisite Flavor)', 'text': '\\n\\n\"Al-Fawarish\" (meaning \"The Treasures\" in Arabic)'}\n"
     ]
    }
   ],
   "source": [
    "name = chain.invoke(\"Arabic\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cc88888",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Mexican\n",
      "AI: \n",
      "\n",
      "\"El Sabor Exquisito\" (The Exquisite Flavor)\n",
      "Human: Arabic\n",
      "AI: \n",
      "\n",
      "\"Al-Fawarish\" (meaning \"The Treasures\" in Arabic)\n"
     ]
    }
   ],
   "source": [
    "print(chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a88b5b",
   "metadata": {},
   "source": [
    "#### ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "687ddd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "convo = ConversationChain(llm=OpenAI(temperature=0.7))\n",
    "print(convo.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47ad5062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Who won the first cricket world cup?',\n",
       " 'history': '',\n",
       " 'response': \" The first cricket world cup was won by the West Indies team in 1975. They beat Australia in the finals, with a score of 291 runs to 274 runs. The match was held at Lord's Cricket Ground in London, England.\"}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.invoke(\"Who won the first cricket world cup?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03c80b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'How much is 5+5?',\n",
       " 'history': \"Human: Who won the first cricket world cup?\\nAI:  The first cricket world cup was won by the West Indies team in 1975. They beat Australia in the finals, with a score of 291 runs to 274 runs. The match was held at Lord's Cricket Ground in London, England.\",\n",
       " 'response': ' 5+5 is equal to 10.'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.invoke(\"How much is 5+5?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07342f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Who was the captain ofthe winning team?',\n",
       " 'history': \"Human: Who won the first cricket world cup?\\nAI:  The first cricket world cup was won by the West Indies team in 1975. They beat Australia in the finals, with a score of 291 runs to 274 runs. The match was held at Lord's Cricket Ground in London, England.\\nHuman: How much is 5+5?\\nAI:  5+5 is equal to 10.\",\n",
       " 'response': ' The captain of the West Indies team in the 1975 World Cup was Clive Lloyd. He was a left-handed batsman and a medium-pace bowler. He also led the team to win the 1979 World Cup.'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.invoke(\"Who was the captain ofthe winning team?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e459d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Who won the first cricket world cup?\n",
      "AI:  The first cricket world cup was won by the West Indies team in 1975. They beat Australia in the finals, with a score of 291 runs to 274 runs. The match was held at Lord's Cricket Ground in London, England.\n",
      "Human: How much is 5+5?\n",
      "AI:  5+5 is equal to 10.\n",
      "Human: Who was the captain ofthe winning team?\n",
      "AI:  The captain of the West Indies team in the 1975 World Cup was Clive Lloyd. He was a left-handed batsman and a medium-pace bowler. He also led the team to win the 1979 World Cup.\n"
     ]
    }
   ],
   "source": [
    "print(convo.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaa3abd",
   "metadata": {},
   "source": [
    "#### ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "460eb33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Who won the first cricket world cup?',\n",
       " 'history': '',\n",
       " 'response': \" The first cricket world cup was won by West Indies in 1975. The final match was played between West Indies and Australia at Lord's Cricket Ground in London. West Indies won by 17 runs, with Clive Lloyd scoring 102 runs for his team. The winning team received a prize money of £4,000 and the runners-up received £2,000. The first ever man of the match award was given to West Indies' Vivian Richards for his outstanding performance in the final.\"}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "\n",
    "convo = ConversationChain(\n",
    "    llm=OpenAI(temperature=0.7),\n",
    "    memory=memory\n",
    ")\n",
    "convo.invoke(\"Who won the first cricket world cup?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d395beaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'How much is 5+5?',\n",
       " 'history': \"Human: Who won the first cricket world cup?\\nAI:  The first cricket world cup was won by West Indies in 1975. The final match was played between West Indies and Australia at Lord's Cricket Ground in London. West Indies won by 17 runs, with Clive Lloyd scoring 102 runs for his team. The winning team received a prize money of £4,000 and the runners-up received £2,000. The first ever man of the match award was given to West Indies' Vivian Richards for his outstanding performance in the final.\",\n",
       " 'response': '  5+5 equals 10.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.invoke(\"How much is 5+5?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93b24745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Who was the captain of the winning team?',\n",
       " 'history': 'Human: How much is 5+5?\\nAI:   5+5 equals 10.',\n",
       " 'response': ' I do not have enough context to answer that question. Can you provide more details about the team and the event?'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.invoke(\"Who was the captain of the winning team?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cd907d",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "047f239e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Who was the captain of the winning team?\n",
      "AI:  I do not have enough context to answer that question. Can you provide more details about the team and the event?\n"
     ]
    }
   ],
   "source": [
    "for chunk in convo.stream(\"Write me a song about goldfish on the moon\"):\n",
    "    print(chunk[\"history\"])\n",
    "    # print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66d61341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_community.llms import GPT4All\n",
    "\n",
    "# Set up the prompt template\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "# Set up the local instace of the LLM\n",
    "local_path = \"/Users/brianroepke/Library/Application Support/nomic.ai/GPT4All/mistral-7b-openorca.Q4_0.gguf\"  # noqa: E501\n",
    "callbacks = [StreamingStdOutCallbackHandler()]\n",
    "memory = ConversationBufferMemory()\n",
    "llm = GPT4All(model=local_path, callbacks=callbacks, verbose=True, streaming=True)  # noqa: E501\n",
    "# llm_chain = LLMChain(llm=llm, prompt=prompt, memory=memory)\n",
    "\n",
    "llm_chain = ConversationChain(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "842b2f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sure! Here's a little ditty I came up with:\n",
      "\n",
      "Sparkling Water Lullaby\n",
      "(To the tune of Twinkle, Twinkle Little Star)\n",
      "\n",
      "Sparkling water so clear and bright,\n",
      "Bubbles dance in the moonlight,\n",
      "Quenching thirst on a summer night.\n",
      "\n",
      "Chorus:\n",
      "Drink it down, drink it up,\n",
      "Feel your body tingle with delight!\n",
      "Sparkling water is so right!\n",
      "\n",
      "In the meadow where daisies play,\n",
      "A cool stream flows all day,\n",
      "Filling glasses for passersby.\n",
      "\n",
      "Chorus: Drink it down...\n",
      "\n",
      "On a mountain peak so high,\n",
      "Icicles glisten in the sky,\n",
      "Melting into sparkling water.\n",
      "\n",
      "Chorus: Drink it down...\n",
      "\n",
      "In the depths of the ocean blue,\n",
      "A school of fish come swimming through,\n",
      "Drinking from fountains made for two.\n",
      "\n",
      "Chorus: Drink it down...\n",
      "\n",
      "So next time you're parched and dry,\n",
      "Remember sparkling water's why,\n",
      "It quenches thirst with every sigh!\n",
      "{'input': 'Write me a song about sparkling water.', 'history': '', 'response': \" Sure! Here's a little ditty I came up with:\\n\\nSparkling Water Lullaby\\n(To the tune of Twinkle, Twinkle Little Star)\\n\\nSparkling water so clear and bright,\\nBubbles dance in the moonlight,\\nQuenching thirst on a summer night.\\n\\nChorus:\\nDrink it down, drink it up,\\nFeel your body tingle with delight!\\nSparkling water is so right!\\n\\nIn the meadow where daisies play,\\nA cool stream flows all day,\\nFilling glasses for passersby.\\n\\nChorus: Drink it down...\\n\\nOn a mountain peak so high,\\nIcicles glisten in the sky,\\nMelting into sparkling water.\\n\\nChorus: Drink it down...\\n\\nIn the depths of the ocean blue,\\nA school of fish come swimming through,\\nDrinking from fountains made for two.\\n\\nChorus: Drink it down...\\n\\nSo next time you're parched and dry,\\nRemember sparkling water's why,\\nIt quenches thirst with every sigh!\\n\"}"
     ]
    }
   ],
   "source": [
    "for chunk in llm_chain.stream(\"Write me a song about sparkling water.\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9292a00c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
